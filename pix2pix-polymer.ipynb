{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11610997,"sourceType":"datasetVersion","datasetId":7282904}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torchvision.utils as vutils\n\n# --- Dataset Class ---\nclass PolymerDataset(Dataset):\n    def __init__(self, input_dir, target_dir, size=(512, 512)):\n        self.input_dir = input_dir\n        self.target_dir = target_dir\n        self.size = size\n        self.filenames = sorted(os.listdir(input_dir))\n        \n        self.transform = transforms.Compose([\n            transforms.Resize(size),\n            transforms.ToTensor(),\n        ])\n    \n    def __len__(self):\n        return len(self.filenames)\n    \n    def __getitem__(self, idx):\n        input_path = os.path.join(self.input_dir, self.filenames[idx])\n        target_path = os.path.join(self.target_dir, self.filenames[idx])\n        \n        input_img = Image.open(input_path).convert('L')\n        target_img = Image.open(target_path).convert('L')\n        \n        input_tensor = self.transform(input_img)\n        target_tensor = self.transform(target_img)\n        \n        input_tensor = (input_tensor > 0.5).float() * 2 - 1\n        target_tensor = (target_tensor > 0.5).float() * 2 - 1\n        \n        return input_tensor, target_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:04:28.091909Z","iopub.execute_input":"2025-04-29T15:04:28.092539Z","iopub.status.idle":"2025-04-29T15:04:34.866650Z","shell.execute_reply.started":"2025-04-29T15:04:28.092515Z","shell.execute_reply":"2025-04-29T15:04:34.866115Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --- UNet Generator ---\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        self.conv_in = nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False)\n        \n        # Downsampling\n        self.down1 = nn.Sequential(\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(128)\n        )\n        self.down2 = self._make_down_block(128, 256)\n        self.down3 = self._make_down_block(256, 512)\n        self.down4 = self._make_down_block(512, 512)\n        self.down5 = self._make_down_block(512, 512)\n        self.down6 = self._make_down_block(512, 512)\n\n        # Middle\n        self.middle = nn.Sequential(\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(512)\n        )\n\n        # Upsampling\n        self.up1 = self._make_up_block(1024, 512, dropout=True)\n        self.up2 = self._make_up_block(1024, 512, dropout=True)\n        self.up3 = self._make_up_block(1024, 512, dropout=True)\n        self.up4 = self._make_up_block(1024, 256)\n        self.up5 = self._make_up_block(512, 128)\n        self.up6 = self._make_up_block(256, 64)\n\n        self.outermost = nn.Sequential(\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(128, 1, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n        )\n\n    def _make_down_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def _make_up_block(self, in_channels, out_channels, dropout=False):\n        layers = [\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels)\n        ]\n        if dropout:\n            layers.append(nn.Dropout(0.5))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        # Encoder\n        x0 = self.conv_in(x)\n        x1 = self.down1(x0)\n        x2 = self.down2(x1)\n        x3 = self.down3(x2)\n        x4 = self.down4(x3)\n        x5 = self.down5(x4)\n        x6 = self.down6(x5)\n\n        # Middle\n        x = self.middle(x6)\n\n        # Decoder with skip connections\n        x = self.up1(torch.cat([x, x6], dim=1))\n        x = self.up2(torch.cat([x, x5], dim=1))\n        x = self.up3(torch.cat([x, x4], dim=1))\n        x = self.up4(torch.cat([x, x3], dim=1))\n        x = self.up5(torch.cat([x, x2], dim=1))\n        x = self.up6(torch.cat([x, x1], dim=1))\n        \n        return self.outermost(torch.cat([x, x0], dim=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:04:37.748487Z","iopub.execute_input":"2025-04-29T15:04:37.749233Z","iopub.status.idle":"2025-04-29T15:04:37.762398Z","shell.execute_reply.started":"2025-04-29T15:04:37.749207Z","shell.execute_reply":"2025-04-29T15:04:37.761704Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# --- PatchGAN Discriminator ---\nclass PatchGAN(nn.Module):\n    def __init__(self):\n        super(PatchGAN, self).__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(2, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n# --- Learning Rate Scheduler ---\nclass LambdaLR:\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n\n    def step(self, epoch):\n        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n\n# --- Visualization Function ---\ndef visualize_results(inputs, targets, outputs, epoch, save_dir=\"training_results\"):\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # Denormalize images\n    inputs = (inputs.cpu().numpy() + 1) / 2\n    targets = (targets.cpu().numpy() + 1) / 2\n    outputs = (outputs.cpu().numpy() + 1) / 2\n    \n    plt.figure(figsize=(15, 5))\n    for i in range(min(3, inputs.shape[0])):  # Show max 3 examples\n        plt.subplot(3, 3, i*3+1)\n        plt.imshow(inputs[i][0], cmap='gray')\n        plt.title(\"Input\")\n        plt.axis('off')\n        \n        plt.subplot(3, 3, i*3+2)\n        plt.imshow(targets[i][0], cmap='gray')\n        plt.title(\"Target\")\n        plt.axis('off')\n        \n        plt.subplot(3, 3, i*3+3)\n        plt.imshow(outputs[i][0], cmap='gray')\n        plt.title(\"Output\")\n        plt.axis('off')\n    \n    plt.suptitle(f\"Epoch {epoch+1}\")\n    plt.savefig(f\"{save_dir}/epoch_{epoch+1}.png\")\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:04:40.544928Z","iopub.execute_input":"2025-04-29T15:04:40.545530Z","iopub.status.idle":"2025-04-29T15:04:40.554974Z","shell.execute_reply.started":"2025-04-29T15:04:40.545506Z","shell.execute_reply":"2025-04-29T15:04:40.554282Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load dataset\ninput_dir = '/kaggle/input/dataset1/sliced images/input'\ntarget_dir = '/kaggle/input/dataset1/sliced images/target'\n    \n\n# Split dataset\ndataset = PolymerDataset(input_dir, target_dir)\n\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ngen = torch.Generator()\ngen.manual_seed(30)\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=gen)\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:04:47.024684Z","iopub.execute_input":"2025-04-29T15:04:47.025259Z","iopub.status.idle":"2025-04-29T15:04:47.063864Z","shell.execute_reply.started":"2025-04-29T15:04:47.025234Z","shell.execute_reply":"2025-04-29T15:04:47.063372Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"len(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:04:50.055137Z","iopub.execute_input":"2025-04-29T15:04:50.055656Z","iopub.status.idle":"2025-04-29T15:04:50.060933Z","shell.execute_reply.started":"2025-04-29T15:04:50.055635Z","shell.execute_reply":"2025-04-29T15:04:50.060102Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"66"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"len(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:04:51.999902Z","iopub.execute_input":"2025-04-29T15:04:52.000557Z","iopub.status.idle":"2025-04-29T15:04:52.004809Z","shell.execute_reply.started":"2025-04-29T15:04:52.000532Z","shell.execute_reply":"2025-04-29T15:04:52.004143Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"264"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# --- Training Function with Visualization ---\ndef train():\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Initialize models\n    netG = UNet().to(device)\n    netD = PatchGAN().to(device)\n    \n    # Loss functions\n    criterion_GAN = nn.BCEWithLogitsLoss()\n    criterion_L1 = nn.L1Loss()\n    lambda_L1 = 20\n    \n    # Optimizers\n    optimizer_G = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    optimizer_D = torch.optim.Adam(netD.parameters(), lr=0.0001, betas=(0.5, 0.999))\n    \n    # Learning rate schedulers\n    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n        optimizer_G, lr_lambda=LambdaLR(100, 0, 50).step)\n    lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(\n        optimizer_D, lr_lambda=LambdaLR(100, 0, 50).step)\n\n    \n    # Create fixed batch for visualization\n    fixed_inputs, fixed_targets = next(iter(test_loader))\n    fixed_inputs = fixed_inputs.to(device)\n    \n    # History tracking\n    history = {\n        'epoch': [],\n        'G_loss': [],\n        'D_loss': [],\n        'D_real': [],\n        'D_fake': [],\n        'D_x': [],       # D(x) - average output on real images\n        'D_G_z': [],     # D(G(z)) - average output on fake images\n        'val_loss': []\n    }\n    \n    # Training loop\n    for epoch in range(100):\n        netG.train()\n        netD.train()\n        \n        # Initialize accumulators\n        running_loss_G = 0.0\n        running_loss_D = 0.0\n        running_loss_D_real = 0.0\n        running_loss_D_fake = 0.0\n        running_D_x = 0.0\n        running_D_G_z = 0.0\n        d_steps = 0\n        \n        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/100')\n        for i, (input_imgs, target_imgs) in enumerate(progress_bar):\n            input_imgs, target_imgs = input_imgs.to(device), target_imgs.to(device)\n            \n            # Train Generator\n            optimizer_G.zero_grad()\n            fake_B = netG(input_imgs)\n            fake_AB = torch.cat((input_imgs, fake_B), 1)\n            \n            pred_fake = netD(fake_AB)\n            loss_G_GAN = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n            loss_G_L1 = criterion_L1(fake_B, target_imgs) * lambda_L1\n            loss_G = loss_G_GAN + loss_G_L1\n            loss_G.backward()\n            optimizer_G.step()\n            \n            running_loss_G += loss_G.item()\n            running_D_G_z += torch.sigmoid(pred_fake).mean().item()\n            \n            # Train Discriminator (every 2nd step)\n            if i % 2 == 0:\n                optimizer_D.zero_grad()\n                \n                # Real images\n                real_AB = torch.cat((input_imgs, target_imgs), 1)\n                pred_real = netD(real_AB)\n                real_labels = torch.rand_like(pred_real)*0.1 + 0.9\n                loss_D_real = criterion_GAN(pred_real, real_labels)\n                \n                # Fake images\n                fake_AB = torch.cat((input_imgs, fake_B.detach()), 1)\n                pred_fake = netD(fake_AB)\n                fake_labels = torch.rand_like(pred_fake)*0.1\n                loss_D_fake = criterion_GAN(pred_fake, fake_labels)\n                \n                loss_D = (loss_D_real + loss_D_fake) * 0.5\n                loss_D.backward()\n                optimizer_D.step()\n                \n                running_loss_D += loss_D.item()\n                running_loss_D_real += loss_D_real.item()\n                running_loss_D_fake += loss_D_fake.item()\n                running_D_x += torch.sigmoid(pred_real).mean().item()\n                d_steps += 1\n            \n            # Update progress bar\n            progress_bar.set_postfix({\n                'G': f'{running_loss_G/(i+1):.4f}',\n                'D': f'{running_loss_D/d_steps:.4f}' if d_steps > 0 else 'skipped',\n                'D(x)': f'{running_D_x/d_steps:.3f}' if d_steps > 0 else '-',\n                'D(G(z))': f'{running_D_G_z/(i+1):.3f}'\n            })\n            \n        # Update learning rates\n        lr_scheduler_G.step()\n        lr_scheduler_D.step()\n        \n        # Validation\n        netG.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for input_imgs, target_imgs in test_loader:\n                input_imgs, target_imgs = input_imgs.to(device), target_imgs.to(device)\n                fake_B = netG(input_imgs)\n                val_loss += criterion_L1(fake_B, target_imgs).item()\n            \n            # Generate visualization\n            fixed_outputs = netG(fixed_inputs)\n            visualize_results(fixed_inputs[:3], fixed_targets[:3].to(device), fixed_outputs[:3], epoch)\n        \n        # Calculate averages\n        avg_loss_G = running_loss_G / len(train_loader)\n        avg_loss_D = running_loss_D / d_steps if d_steps > 0 else 0\n        avg_loss_D_real = running_loss_D_real / d_steps if d_steps > 0 else 0\n        avg_loss_D_fake = running_loss_D_fake / d_steps if d_steps > 0 else 0\n        avg_D_x = running_D_x / d_steps if d_steps > 0 else 0\n        avg_D_G_z = running_D_G_z / len(train_loader)\n        avg_val_loss = val_loss / len(test_loader)\n        \n        # Store history\n        history['epoch'].append(epoch+1)\n        history['G_loss'].append(avg_loss_G)\n        history['D_loss'].append(avg_loss_D)\n        history['D_real'].append(avg_loss_D_real)\n        history['D_fake'].append(avg_loss_D_fake)\n        history['D_x'].append(avg_D_x)\n        history['D_G_z'].append(avg_D_G_z)\n        history['val_loss'].append(avg_val_loss)\n        \n        # Print epoch summary\n        print(f'\\nEpoch {epoch+1} Summary:')\n        print(f'G_loss: {avg_loss_G:.4f} | D_loss: {avg_loss_D:.4f}')\n        print(f'D_real: {avg_loss_D_real:.4f} | D_fake: {avg_loss_D_fake:.4f}')\n        print(f'D(x): {avg_D_x:.3f} | D(G(z)): {avg_D_G_z:.3f}')\n        print(f'Val Loss: {avg_val_loss:.4f}')\n        \n        # Save models\n        if (epoch + 1) % 10 == 0:\n            torch.save(netG.state_dict(), f'generator_epoch_{epoch+1}.pth')\n            torch.save(netD.state_dict(), f'discriminator_epoch_{epoch+1}.pth')\n    \n    # Save final models\n    torch.save(netG.state_dict(), 'generator_final.pth')\n    torch.save(netD.state_dict(), 'discriminator_final.pth')\n    \n    # Plot training history\n    plot_training_history(history)\n\ndef plot_training_history(history):\n    plt.figure(figsize=(15, 10))\n    \n    # Loss plot\n    plt.subplot(2, 2, 1)\n    plt.plot(history['epoch'], history['G_loss'], label='Generator Loss')\n    plt.plot(history['epoch'], history['D_loss'], label='Discriminator Loss')\n    plt.plot(history['epoch'], history['val_loss'], label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Losses')\n    plt.legend()\n    \n    # D(x) and D(G(z)) plot\n    plt.subplot(2, 2, 2)\n    plt.plot(history['epoch'], history['D_x'], label='D(x) - Real')\n    plt.plot(history['epoch'], history['D_G_z'], label='D(G(z)) - Fake')\n    plt.xlabel('Epoch')\n    plt.ylabel('Score')\n    plt.title('Discriminator Output Scores')\n    plt.legend()\n    \n    # D components plot\n    plt.subplot(2, 2, 3)\n    plt.plot(history['epoch'], history['D_real'], label='D Real Loss')\n    plt.plot(history['epoch'], history['D_fake'], label='D Fake Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Discriminator Component Losses')\n    plt.legend()\n    \n    # Save plots\n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.close()\n\nif __name__ == \"__main__\":\n    train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:05:09.358443Z","iopub.execute_input":"2025-04-29T15:05:09.358722Z","iopub.status.idle":"2025-04-29T17:28:32.549510Z","shell.execute_reply.started":"2025-04-29T15:05:09.358700Z","shell.execute_reply":"2025-04-29T17:28:32.548934Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/100: 100%|██████████| 264/264 [01:33<00:00,  2.83it/s, G=7.3922, D=0.6139, D(x)=0.563, D(G(z))=0.432]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Summary:\nG_loss: 7.3922 | D_loss: 0.6139\nD_real: 0.6194 | D_fake: 0.6084\nD(x): 0.563 | D(G(z)): 0.432\nVal Loss: 0.3928\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=8.0334, D=0.4943, D(x)=0.666, D(G(z))=0.336]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Summary:\nG_loss: 8.0334 | D_loss: 0.4943\nD_real: 0.5096 | D_fake: 0.4791\nD(x): 0.666 | D(G(z)): 0.336\nVal Loss: 0.3720\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=8.1279, D=0.5385, D(x)=0.645, D(G(z))=0.353]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Summary:\nG_loss: 8.1279 | D_loss: 0.5385\nD_real: 0.5733 | D_fake: 0.5037\nD(x): 0.645 | D(G(z)): 0.353\nVal Loss: 0.3970\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=7.9506, D=0.5647, D(x)=0.621, D(G(z))=0.374]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 Summary:\nG_loss: 7.9506 | D_loss: 0.5647\nD_real: 0.6009 | D_fake: 0.5284\nD(x): 0.621 | D(G(z)): 0.374\nVal Loss: 0.3347\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=7.8266, D=0.5753, D(x)=0.609, D(G(z))=0.389]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 Summary:\nG_loss: 7.8266 | D_loss: 0.5753\nD_real: 0.6029 | D_fake: 0.5478\nD(x): 0.609 | D(G(z)): 0.389\nVal Loss: 0.3332\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=7.7062, D=0.5902, D(x)=0.596, D(G(z))=0.399]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 Summary:\nG_loss: 7.7062 | D_loss: 0.5902\nD_real: 0.6072 | D_fake: 0.5732\nD(x): 0.596 | D(G(z)): 0.399\nVal Loss: 0.3183\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=7.6210, D=0.5883, D(x)=0.595, D(G(z))=0.401]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 Summary:\nG_loss: 7.6210 | D_loss: 0.5883\nD_real: 0.6116 | D_fake: 0.5651\nD(x): 0.595 | D(G(z)): 0.401\nVal Loss: 0.3053\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=7.5021, D=0.5953, D(x)=0.591, D(G(z))=0.416]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 Summary:\nG_loss: 7.5021 | D_loss: 0.5953\nD_real: 0.6052 | D_fake: 0.5853\nD(x): 0.591 | D(G(z)): 0.416\nVal Loss: 0.3551\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=7.4981, D=0.5936, D(x)=0.591, D(G(z))=0.408]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 Summary:\nG_loss: 7.4981 | D_loss: 0.5936\nD_real: 0.6121 | D_fake: 0.5750\nD(x): 0.591 | D(G(z)): 0.408\nVal Loss: 0.3219\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=7.3453, D=0.5967, D(x)=0.587, D(G(z))=0.418]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 Summary:\nG_loss: 7.3453 | D_loss: 0.5967\nD_real: 0.6032 | D_fake: 0.5901\nD(x): 0.587 | D(G(z)): 0.418\nVal Loss: 0.3438\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=7.4410, D=0.6017, D(x)=0.588, D(G(z))=0.400]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11 Summary:\nG_loss: 7.4410 | D_loss: 0.6017\nD_real: 0.6200 | D_fake: 0.5834\nD(x): 0.588 | D(G(z)): 0.400\nVal Loss: 0.3087\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=7.2515, D=0.6000, D(x)=0.583, D(G(z))=0.422]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12 Summary:\nG_loss: 7.2515 | D_loss: 0.6000\nD_real: 0.6059 | D_fake: 0.5940\nD(x): 0.583 | D(G(z)): 0.422\nVal Loss: 0.3079\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=7.2081, D=0.6064, D(x)=0.578, D(G(z))=0.420]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13 Summary:\nG_loss: 7.2081 | D_loss: 0.6064\nD_real: 0.6154 | D_fake: 0.5974\nD(x): 0.578 | D(G(z)): 0.420\nVal Loss: 0.3370\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=7.1540, D=0.6044, D(x)=0.576, D(G(z))=0.422]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14 Summary:\nG_loss: 7.1540 | D_loss: 0.6044\nD_real: 0.6109 | D_fake: 0.5979\nD(x): 0.576 | D(G(z)): 0.422\nVal Loss: 0.3332\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=7.1704, D=0.6042, D(x)=0.577, D(G(z))=0.421]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15 Summary:\nG_loss: 7.1704 | D_loss: 0.6042\nD_real: 0.6140 | D_fake: 0.5945\nD(x): 0.577 | D(G(z)): 0.421\nVal Loss: 0.3138\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=7.0822, D=0.6087, D(x)=0.578, D(G(z))=0.418]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16 Summary:\nG_loss: 7.0822 | D_loss: 0.6087\nD_real: 0.6151 | D_fake: 0.6023\nD(x): 0.578 | D(G(z)): 0.418\nVal Loss: 0.3134\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.9573, D=0.6006, D(x)=0.577, D(G(z))=0.424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17 Summary:\nG_loss: 6.9573 | D_loss: 0.6006\nD_real: 0.6074 | D_fake: 0.5938\nD(x): 0.577 | D(G(z)): 0.424\nVal Loss: 0.3260\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.9196, D=0.6057, D(x)=0.576, D(G(z))=0.436]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18 Summary:\nG_loss: 6.9196 | D_loss: 0.6057\nD_real: 0.6062 | D_fake: 0.6052\nD(x): 0.576 | D(G(z)): 0.436\nVal Loss: 0.3207\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.8960, D=0.6173, D(x)=0.575, D(G(z))=0.430]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19 Summary:\nG_loss: 6.8960 | D_loss: 0.6173\nD_real: 0.6229 | D_fake: 0.6118\nD(x): 0.575 | D(G(z)): 0.430\nVal Loss: 0.3378\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.7901, D=0.6049, D(x)=0.576, D(G(z))=0.423]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20 Summary:\nG_loss: 6.7901 | D_loss: 0.6049\nD_real: 0.6085 | D_fake: 0.6013\nD(x): 0.576 | D(G(z)): 0.423\nVal Loss: 0.3295\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.7477, D=0.6049, D(x)=0.577, D(G(z))=0.422]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21 Summary:\nG_loss: 6.7477 | D_loss: 0.6049\nD_real: 0.6123 | D_fake: 0.5975\nD(x): 0.577 | D(G(z)): 0.422\nVal Loss: 0.3349\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.6178, D=0.6062, D(x)=0.576, D(G(z))=0.421]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22 Summary:\nG_loss: 6.6178 | D_loss: 0.6062\nD_real: 0.6087 | D_fake: 0.6036\nD(x): 0.576 | D(G(z)): 0.421\nVal Loss: 0.3221\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.5763, D=0.6135, D(x)=0.576, D(G(z))=0.427]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23 Summary:\nG_loss: 6.5763 | D_loss: 0.6135\nD_real: 0.6123 | D_fake: 0.6148\nD(x): 0.576 | D(G(z)): 0.427\nVal Loss: 0.3264\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.4958, D=0.6025, D(x)=0.578, D(G(z))=0.419]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24 Summary:\nG_loss: 6.4958 | D_loss: 0.6025\nD_real: 0.6090 | D_fake: 0.5959\nD(x): 0.578 | D(G(z)): 0.419\nVal Loss: 0.3168\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.6550, D=0.6058, D(x)=0.579, D(G(z))=0.418]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25 Summary:\nG_loss: 6.6550 | D_loss: 0.6058\nD_real: 0.6155 | D_fake: 0.5961\nD(x): 0.579 | D(G(z)): 0.418\nVal Loss: 0.3208\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.4146, D=0.6072, D(x)=0.580, D(G(z))=0.422]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26 Summary:\nG_loss: 6.4146 | D_loss: 0.6072\nD_real: 0.6083 | D_fake: 0.6060\nD(x): 0.580 | D(G(z)): 0.422\nVal Loss: 0.3235\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3497, D=0.6021, D(x)=0.573, D(G(z))=0.423]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27 Summary:\nG_loss: 6.3497 | D_loss: 0.6021\nD_real: 0.6069 | D_fake: 0.5973\nD(x): 0.573 | D(G(z)): 0.423\nVal Loss: 0.3417\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3763, D=0.5970, D(x)=0.581, D(G(z))=0.419]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28 Summary:\nG_loss: 6.3763 | D_loss: 0.5970\nD_real: 0.6025 | D_fake: 0.5916\nD(x): 0.581 | D(G(z)): 0.419\nVal Loss: 0.3271\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3688, D=0.6007, D(x)=0.576, D(G(z))=0.417]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29 Summary:\nG_loss: 6.3688 | D_loss: 0.6007\nD_real: 0.6040 | D_fake: 0.5975\nD(x): 0.576 | D(G(z)): 0.417\nVal Loss: 0.3317\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3337, D=0.5932, D(x)=0.585, D(G(z))=0.418]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30 Summary:\nG_loss: 6.3337 | D_loss: 0.5932\nD_real: 0.5952 | D_fake: 0.5912\nD(x): 0.585 | D(G(z)): 0.418\nVal Loss: 0.3330\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.3220, D=0.6000, D(x)=0.580, D(G(z))=0.416]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31 Summary:\nG_loss: 6.3220 | D_loss: 0.6000\nD_real: 0.6056 | D_fake: 0.5945\nD(x): 0.580 | D(G(z)): 0.416\nVal Loss: 0.3358\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3405, D=0.5971, D(x)=0.582, D(G(z))=0.413]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32 Summary:\nG_loss: 6.3405 | D_loss: 0.5971\nD_real: 0.6009 | D_fake: 0.5933\nD(x): 0.582 | D(G(z)): 0.413\nVal Loss: 0.3381\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3113, D=0.6021, D(x)=0.580, D(G(z))=0.416]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33 Summary:\nG_loss: 6.3113 | D_loss: 0.6021\nD_real: 0.6088 | D_fake: 0.5953\nD(x): 0.580 | D(G(z)): 0.416\nVal Loss: 0.3189\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3117, D=0.5965, D(x)=0.584, D(G(z))=0.409]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34 Summary:\nG_loss: 6.3117 | D_loss: 0.5965\nD_real: 0.5965 | D_fake: 0.5965\nD(x): 0.584 | D(G(z)): 0.409\nVal Loss: 0.3326\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2873, D=0.5926, D(x)=0.585, D(G(z))=0.419]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 35 Summary:\nG_loss: 6.2873 | D_loss: 0.5926\nD_real: 0.5944 | D_fake: 0.5908\nD(x): 0.585 | D(G(z)): 0.419\nVal Loss: 0.3214\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3069, D=0.5963, D(x)=0.583, D(G(z))=0.410]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 36 Summary:\nG_loss: 6.3069 | D_loss: 0.5963\nD_real: 0.6009 | D_fake: 0.5916\nD(x): 0.583 | D(G(z)): 0.410\nVal Loss: 0.3271\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.2145, D=0.5942, D(x)=0.586, D(G(z))=0.412]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 37 Summary:\nG_loss: 6.2145 | D_loss: 0.5942\nD_real: 0.5995 | D_fake: 0.5889\nD(x): 0.586 | D(G(z)): 0.412\nVal Loss: 0.3267\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2565, D=0.5940, D(x)=0.583, D(G(z))=0.417]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 38 Summary:\nG_loss: 6.2565 | D_loss: 0.5940\nD_real: 0.5927 | D_fake: 0.5954\nD(x): 0.583 | D(G(z)): 0.417\nVal Loss: 0.3422\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2398, D=0.5967, D(x)=0.583, D(G(z))=0.409]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 39 Summary:\nG_loss: 6.2398 | D_loss: 0.5967\nD_real: 0.6011 | D_fake: 0.5922\nD(x): 0.583 | D(G(z)): 0.409\nVal Loss: 0.3380\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2315, D=0.5947, D(x)=0.584, D(G(z))=0.413]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 40 Summary:\nG_loss: 6.2315 | D_loss: 0.5947\nD_real: 0.5960 | D_fake: 0.5935\nD(x): 0.584 | D(G(z)): 0.413\nVal Loss: 0.3350\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2536, D=0.5952, D(x)=0.584, D(G(z))=0.408]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 41 Summary:\nG_loss: 6.2536 | D_loss: 0.5952\nD_real: 0.5952 | D_fake: 0.5951\nD(x): 0.584 | D(G(z)): 0.408\nVal Loss: 0.3548\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2032, D=0.5937, D(x)=0.584, D(G(z))=0.412]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 42 Summary:\nG_loss: 6.2032 | D_loss: 0.5937\nD_real: 0.5969 | D_fake: 0.5904\nD(x): 0.584 | D(G(z)): 0.412\nVal Loss: 0.3374\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.2305, D=0.6000, D(x)=0.585, D(G(z))=0.410]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 43 Summary:\nG_loss: 6.2305 | D_loss: 0.6000\nD_real: 0.6031 | D_fake: 0.5968\nD(x): 0.585 | D(G(z)): 0.410\nVal Loss: 0.3251\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2941, D=0.5933, D(x)=0.587, D(G(z))=0.413]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 44 Summary:\nG_loss: 6.2941 | D_loss: 0.5933\nD_real: 0.5980 | D_fake: 0.5887\nD(x): 0.587 | D(G(z)): 0.413\nVal Loss: 0.3409\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2357, D=0.5882, D(x)=0.589, D(G(z))=0.410]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 45 Summary:\nG_loss: 6.2357 | D_loss: 0.5882\nD_real: 0.5882 | D_fake: 0.5882\nD(x): 0.589 | D(G(z)): 0.410\nVal Loss: 0.3211\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2367, D=0.5778, D(x)=0.591, D(G(z))=0.407]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 46 Summary:\nG_loss: 6.2367 | D_loss: 0.5778\nD_real: 0.5808 | D_fake: 0.5749\nD(x): 0.591 | D(G(z)): 0.407\nVal Loss: 0.3287\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2617, D=0.5981, D(x)=0.589, D(G(z))=0.409]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 47 Summary:\nG_loss: 6.2617 | D_loss: 0.5981\nD_real: 0.6045 | D_fake: 0.5918\nD(x): 0.589 | D(G(z)): 0.409\nVal Loss: 0.3320\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.2181, D=0.5827, D(x)=0.592, D(G(z))=0.410]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 48 Summary:\nG_loss: 6.2181 | D_loss: 0.5827\nD_real: 0.5861 | D_fake: 0.5793\nD(x): 0.592 | D(G(z)): 0.410\nVal Loss: 0.3291\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2538, D=0.5832, D(x)=0.590, D(G(z))=0.401]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 49 Summary:\nG_loss: 6.2538 | D_loss: 0.5832\nD_real: 0.5891 | D_fake: 0.5772\nD(x): 0.590 | D(G(z)): 0.401\nVal Loss: 0.3562\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2467, D=0.5863, D(x)=0.592, D(G(z))=0.410]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 50 Summary:\nG_loss: 6.2467 | D_loss: 0.5863\nD_real: 0.5858 | D_fake: 0.5869\nD(x): 0.592 | D(G(z)): 0.410\nVal Loss: 0.3260\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3212, D=0.6145, D(x)=0.587, D(G(z))=0.407]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 51 Summary:\nG_loss: 6.3212 | D_loss: 0.6145\nD_real: 0.6177 | D_fake: 0.6113\nD(x): 0.587 | D(G(z)): 0.407\nVal Loss: 0.3196\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.1859, D=0.5764, D(x)=0.590, D(G(z))=0.409]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 52 Summary:\nG_loss: 6.1859 | D_loss: 0.5764\nD_real: 0.5771 | D_fake: 0.5756\nD(x): 0.590 | D(G(z)): 0.409\nVal Loss: 0.3270\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2601, D=0.5791, D(x)=0.592, D(G(z))=0.402]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 53 Summary:\nG_loss: 6.2601 | D_loss: 0.5791\nD_real: 0.5824 | D_fake: 0.5759\nD(x): 0.592 | D(G(z)): 0.402\nVal Loss: 0.3487\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2590, D=0.5788, D(x)=0.595, D(G(z))=0.402]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 54 Summary:\nG_loss: 6.2590 | D_loss: 0.5788\nD_real: 0.5799 | D_fake: 0.5777\nD(x): 0.595 | D(G(z)): 0.402\nVal Loss: 0.3506\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2598, D=0.5824, D(x)=0.597, D(G(z))=0.402]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 55 Summary:\nG_loss: 6.2598 | D_loss: 0.5824\nD_real: 0.5829 | D_fake: 0.5818\nD(x): 0.597 | D(G(z)): 0.402\nVal Loss: 0.3446\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2720, D=0.5767, D(x)=0.593, D(G(z))=0.407]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 56 Summary:\nG_loss: 6.2720 | D_loss: 0.5767\nD_real: 0.5782 | D_fake: 0.5751\nD(x): 0.593 | D(G(z)): 0.407\nVal Loss: 0.3276\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2741, D=0.5734, D(x)=0.596, D(G(z))=0.399]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 57 Summary:\nG_loss: 6.2741 | D_loss: 0.5734\nD_real: 0.5743 | D_fake: 0.5725\nD(x): 0.596 | D(G(z)): 0.399\nVal Loss: 0.3346\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58/100: 100%|██████████| 264/264 [01:18<00:00,  3.36it/s, G=6.2884, D=0.5744, D(x)=0.597, D(G(z))=0.401]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 58 Summary:\nG_loss: 6.2884 | D_loss: 0.5744\nD_real: 0.5778 | D_fake: 0.5709\nD(x): 0.597 | D(G(z)): 0.401\nVal Loss: 0.3304\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3129, D=0.5729, D(x)=0.597, D(G(z))=0.396]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 59 Summary:\nG_loss: 6.3129 | D_loss: 0.5729\nD_real: 0.5770 | D_fake: 0.5688\nD(x): 0.597 | D(G(z)): 0.396\nVal Loss: 0.3260\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3094, D=0.5665, D(x)=0.602, D(G(z))=0.395]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 60 Summary:\nG_loss: 6.3094 | D_loss: 0.5665\nD_real: 0.5678 | D_fake: 0.5653\nD(x): 0.602 | D(G(z)): 0.395\nVal Loss: 0.3391\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3023, D=0.5622, D(x)=0.603, D(G(z))=0.390]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 61 Summary:\nG_loss: 6.3023 | D_loss: 0.5622\nD_real: 0.5632 | D_fake: 0.5613\nD(x): 0.603 | D(G(z)): 0.390\nVal Loss: 0.3394\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2990, D=0.5640, D(x)=0.605, D(G(z))=0.394]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 62 Summary:\nG_loss: 6.2990 | D_loss: 0.5640\nD_real: 0.5622 | D_fake: 0.5657\nD(x): 0.605 | D(G(z)): 0.394\nVal Loss: 0.3376\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3059, D=0.5741, D(x)=0.603, D(G(z))=0.391]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 63 Summary:\nG_loss: 6.3059 | D_loss: 0.5741\nD_real: 0.5755 | D_fake: 0.5726\nD(x): 0.603 | D(G(z)): 0.391\nVal Loss: 0.3386\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2897, D=0.5486, D(x)=0.610, D(G(z))=0.389]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 64 Summary:\nG_loss: 6.2897 | D_loss: 0.5486\nD_real: 0.5503 | D_fake: 0.5469\nD(x): 0.610 | D(G(z)): 0.389\nVal Loss: 0.3336\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3116, D=0.5567, D(x)=0.607, D(G(z))=0.388]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 65 Summary:\nG_loss: 6.3116 | D_loss: 0.5567\nD_real: 0.5587 | D_fake: 0.5546\nD(x): 0.607 | D(G(z)): 0.388\nVal Loss: 0.3471\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2945, D=0.5630, D(x)=0.607, D(G(z))=0.389]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 66 Summary:\nG_loss: 6.2945 | D_loss: 0.5630\nD_real: 0.5637 | D_fake: 0.5623\nD(x): 0.607 | D(G(z)): 0.389\nVal Loss: 0.3344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3081, D=0.5439, D(x)=0.614, D(G(z))=0.382]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 67 Summary:\nG_loss: 6.3081 | D_loss: 0.5439\nD_real: 0.5462 | D_fake: 0.5416\nD(x): 0.614 | D(G(z)): 0.382\nVal Loss: 0.3266\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3353, D=0.5454, D(x)=0.616, D(G(z))=0.381]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 68 Summary:\nG_loss: 6.3353 | D_loss: 0.5454\nD_real: 0.5452 | D_fake: 0.5456\nD(x): 0.616 | D(G(z)): 0.381\nVal Loss: 0.3360\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3204, D=0.5515, D(x)=0.614, D(G(z))=0.383]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 69 Summary:\nG_loss: 6.3204 | D_loss: 0.5515\nD_real: 0.5569 | D_fake: 0.5461\nD(x): 0.614 | D(G(z)): 0.383\nVal Loss: 0.3290\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3055, D=0.5338, D(x)=0.621, D(G(z))=0.376]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 70 Summary:\nG_loss: 6.3055 | D_loss: 0.5338\nD_real: 0.5361 | D_fake: 0.5315\nD(x): 0.621 | D(G(z)): 0.376\nVal Loss: 0.3551\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.3138, D=0.5335, D(x)=0.620, D(G(z))=0.379]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 71 Summary:\nG_loss: 6.3138 | D_loss: 0.5335\nD_real: 0.5355 | D_fake: 0.5316\nD(x): 0.620 | D(G(z)): 0.379\nVal Loss: 0.3362\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.3605, D=0.5373, D(x)=0.623, D(G(z))=0.375]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 72 Summary:\nG_loss: 6.3605 | D_loss: 0.5373\nD_real: 0.5402 | D_fake: 0.5343\nD(x): 0.623 | D(G(z)): 0.375\nVal Loss: 0.3309\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3396, D=0.5246, D(x)=0.627, D(G(z))=0.372]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 73 Summary:\nG_loss: 6.3396 | D_loss: 0.5246\nD_real: 0.5246 | D_fake: 0.5246\nD(x): 0.627 | D(G(z)): 0.372\nVal Loss: 0.3416\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3509, D=0.5171, D(x)=0.629, D(G(z))=0.369]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 74 Summary:\nG_loss: 6.3509 | D_loss: 0.5171\nD_real: 0.5190 | D_fake: 0.5153\nD(x): 0.629 | D(G(z)): 0.369\nVal Loss: 0.3317\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3438, D=0.5300, D(x)=0.626, D(G(z))=0.371]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 75 Summary:\nG_loss: 6.3438 | D_loss: 0.5300\nD_real: 0.5315 | D_fake: 0.5285\nD(x): 0.626 | D(G(z)): 0.371\nVal Loss: 0.3329\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3304, D=0.5245, D(x)=0.628, D(G(z))=0.375]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 76 Summary:\nG_loss: 6.3304 | D_loss: 0.5245\nD_real: 0.5251 | D_fake: 0.5240\nD(x): 0.628 | D(G(z)): 0.375\nVal Loss: 0.3275\n","output_type":"stream"},{"name":"stderr","text":"Epoch 77/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3294, D=0.5201, D(x)=0.630, D(G(z))=0.368]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 77 Summary:\nG_loss: 6.3294 | D_loss: 0.5201\nD_real: 0.5219 | D_fake: 0.5183\nD(x): 0.630 | D(G(z)): 0.368\nVal Loss: 0.3246\n","output_type":"stream"},{"name":"stderr","text":"Epoch 78/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3572, D=0.5119, D(x)=0.634, D(G(z))=0.365]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 78 Summary:\nG_loss: 6.3572 | D_loss: 0.5119\nD_real: 0.5128 | D_fake: 0.5110\nD(x): 0.634 | D(G(z)): 0.365\nVal Loss: 0.3414\n","output_type":"stream"},{"name":"stderr","text":"Epoch 79/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3716, D=0.5184, D(x)=0.631, D(G(z))=0.361]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 79 Summary:\nG_loss: 6.3716 | D_loss: 0.5184\nD_real: 0.5204 | D_fake: 0.5165\nD(x): 0.631 | D(G(z)): 0.361\nVal Loss: 0.3275\n","output_type":"stream"},{"name":"stderr","text":"Epoch 80/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3710, D=0.5062, D(x)=0.639, D(G(z))=0.358]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 80 Summary:\nG_loss: 6.3710 | D_loss: 0.5062\nD_real: 0.5076 | D_fake: 0.5048\nD(x): 0.639 | D(G(z)): 0.358\nVal Loss: 0.3370\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3573, D=0.5084, D(x)=0.639, D(G(z))=0.360]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 81 Summary:\nG_loss: 6.3573 | D_loss: 0.5084\nD_real: 0.5074 | D_fake: 0.5093\nD(x): 0.639 | D(G(z)): 0.360\nVal Loss: 0.3329\n","output_type":"stream"},{"name":"stderr","text":"Epoch 82/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3457, D=0.4948, D(x)=0.645, D(G(z))=0.359]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 82 Summary:\nG_loss: 6.3457 | D_loss: 0.4948\nD_real: 0.4969 | D_fake: 0.4927\nD(x): 0.645 | D(G(z)): 0.359\nVal Loss: 0.3383\n","output_type":"stream"},{"name":"stderr","text":"Epoch 83/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.3360, D=0.5042, D(x)=0.639, D(G(z))=0.356]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 83 Summary:\nG_loss: 6.3360 | D_loss: 0.5042\nD_real: 0.5068 | D_fake: 0.5016\nD(x): 0.639 | D(G(z)): 0.356\nVal Loss: 0.3309\n","output_type":"stream"},{"name":"stderr","text":"Epoch 84/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.3156, D=0.4979, D(x)=0.646, D(G(z))=0.359]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 84 Summary:\nG_loss: 6.3156 | D_loss: 0.4979\nD_real: 0.4963 | D_fake: 0.4995\nD(x): 0.646 | D(G(z)): 0.359\nVal Loss: 0.3317\n","output_type":"stream"},{"name":"stderr","text":"Epoch 85/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3574, D=0.4889, D(x)=0.648, D(G(z))=0.349]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 85 Summary:\nG_loss: 6.3574 | D_loss: 0.4889\nD_real: 0.4918 | D_fake: 0.4859\nD(x): 0.648 | D(G(z)): 0.349\nVal Loss: 0.3474\n","output_type":"stream"},{"name":"stderr","text":"Epoch 86/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.3008, D=0.4918, D(x)=0.649, D(G(z))=0.352]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 86 Summary:\nG_loss: 6.3008 | D_loss: 0.4918\nD_real: 0.4906 | D_fake: 0.4929\nD(x): 0.649 | D(G(z)): 0.352\nVal Loss: 0.3344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 87/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3325, D=0.4835, D(x)=0.654, D(G(z))=0.343]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 87 Summary:\nG_loss: 6.3325 | D_loss: 0.4835\nD_real: 0.4855 | D_fake: 0.4816\nD(x): 0.654 | D(G(z)): 0.343\nVal Loss: 0.3324\n","output_type":"stream"},{"name":"stderr","text":"Epoch 88/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.3266, D=0.4829, D(x)=0.654, D(G(z))=0.343]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 88 Summary:\nG_loss: 6.3266 | D_loss: 0.4829\nD_real: 0.4845 | D_fake: 0.4813\nD(x): 0.654 | D(G(z)): 0.343\nVal Loss: 0.3374\n","output_type":"stream"},{"name":"stderr","text":"Epoch 89/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.3100, D=0.4777, D(x)=0.657, D(G(z))=0.343]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 89 Summary:\nG_loss: 6.3100 | D_loss: 0.4777\nD_real: 0.4780 | D_fake: 0.4774\nD(x): 0.657 | D(G(z)): 0.343\nVal Loss: 0.3369\n","output_type":"stream"},{"name":"stderr","text":"Epoch 90/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.2978, D=0.4819, D(x)=0.654, D(G(z))=0.346]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 90 Summary:\nG_loss: 6.2978 | D_loss: 0.4819\nD_real: 0.4824 | D_fake: 0.4814\nD(x): 0.654 | D(G(z)): 0.346\nVal Loss: 0.3337\n","output_type":"stream"},{"name":"stderr","text":"Epoch 91/100: 100%|██████████| 264/264 [01:18<00:00,  3.34it/s, G=6.2838, D=0.4736, D(x)=0.658, D(G(z))=0.346]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 91 Summary:\nG_loss: 6.2838 | D_loss: 0.4736\nD_real: 0.4752 | D_fake: 0.4720\nD(x): 0.658 | D(G(z)): 0.346\nVal Loss: 0.3321\n","output_type":"stream"},{"name":"stderr","text":"Epoch 92/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2943, D=0.4653, D(x)=0.664, D(G(z))=0.334]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 92 Summary:\nG_loss: 6.2943 | D_loss: 0.4653\nD_real: 0.4647 | D_fake: 0.4659\nD(x): 0.664 | D(G(z)): 0.334\nVal Loss: 0.3347\n","output_type":"stream"},{"name":"stderr","text":"Epoch 93/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2749, D=0.4704, D(x)=0.661, D(G(z))=0.336]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 93 Summary:\nG_loss: 6.2749 | D_loss: 0.4704\nD_real: 0.4710 | D_fake: 0.4698\nD(x): 0.661 | D(G(z)): 0.336\nVal Loss: 0.3286\n","output_type":"stream"},{"name":"stderr","text":"Epoch 94/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2509, D=0.4661, D(x)=0.663, D(G(z))=0.342]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 94 Summary:\nG_loss: 6.2509 | D_loss: 0.4661\nD_real: 0.4666 | D_fake: 0.4656\nD(x): 0.663 | D(G(z)): 0.342\nVal Loss: 0.3334\n","output_type":"stream"},{"name":"stderr","text":"Epoch 95/100: 100%|██████████| 264/264 [01:19<00:00,  3.32it/s, G=6.3143, D=0.4753, D(x)=0.656, D(G(z))=0.341]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 95 Summary:\nG_loss: 6.3143 | D_loss: 0.4753\nD_real: 0.4755 | D_fake: 0.4752\nD(x): 0.656 | D(G(z)): 0.341\nVal Loss: 0.3326\n","output_type":"stream"},{"name":"stderr","text":"Epoch 96/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.2565, D=0.4695, D(x)=0.660, D(G(z))=0.340]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 96 Summary:\nG_loss: 6.2565 | D_loss: 0.4695\nD_real: 0.4704 | D_fake: 0.4686\nD(x): 0.660 | D(G(z)): 0.340\nVal Loss: 0.3332\n","output_type":"stream"},{"name":"stderr","text":"Epoch 97/100: 100%|██████████| 264/264 [01:19<00:00,  3.34it/s, G=6.2411, D=0.4647, D(x)=0.663, D(G(z))=0.337]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 97 Summary:\nG_loss: 6.2411 | D_loss: 0.4647\nD_real: 0.4657 | D_fake: 0.4638\nD(x): 0.663 | D(G(z)): 0.337\nVal Loss: 0.3344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 98/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.2421, D=0.4583, D(x)=0.670, D(G(z))=0.339]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 98 Summary:\nG_loss: 6.2421 | D_loss: 0.4583\nD_real: 0.4575 | D_fake: 0.4592\nD(x): 0.670 | D(G(z)): 0.339\nVal Loss: 0.3346\n","output_type":"stream"},{"name":"stderr","text":"Epoch 99/100: 100%|██████████| 264/264 [01:18<00:00,  3.35it/s, G=6.2323, D=0.4565, D(x)=0.671, D(G(z))=0.333]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 99 Summary:\nG_loss: 6.2323 | D_loss: 0.4565\nD_real: 0.4549 | D_fake: 0.4582\nD(x): 0.671 | D(G(z)): 0.333\nVal Loss: 0.3282\n","output_type":"stream"},{"name":"stderr","text":"Epoch 100/100: 100%|██████████| 264/264 [01:19<00:00,  3.33it/s, G=6.2235, D=0.4590, D(x)=0.666, D(G(z))=0.337]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 100 Summary:\nG_loss: 6.2235 | D_loss: 0.4590\nD_real: 0.4599 | D_fake: 0.4582\nD(x): 0.666 | D(G(z)): 0.337\nVal Loss: 0.3323\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:32:43.647221Z","iopub.execute_input":"2025-04-29T17:32:43.647492Z","iopub.status.idle":"2025-04-29T17:32:43.651397Z","shell.execute_reply.started":"2025-04-29T17:32:43.647471Z","shell.execute_reply":"2025-04-29T17:32:43.650672Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"len(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:32:53.706359Z","iopub.execute_input":"2025-04-29T17:32:53.707055Z","iopub.status.idle":"2025-04-29T17:32:53.711320Z","shell.execute_reply.started":"2025-04-29T17:32:53.707031Z","shell.execute_reply":"2025-04-29T17:32:53.710689Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"264"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision.utils as vutils\nimport os\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport numpy as np\n\ndef inference(checkpoint_path, input_dir, target_dir, save_dir='predictions', num_samples=10):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Загрузка модели\n    netG = UNet().to(device)\n    netG.load_state_dict(torch.load(checkpoint_path, map_location=device))\n    netG.eval()\n\n\n    os.makedirs(save_dir, exist_ok=True)\n    mask_dir = os.path.join(save_dir, 'predicted_masks')\n    os.makedirs(mask_dir, exist_ok=True)\n\n    with torch.no_grad():\n        for idx, (input_img, target_img) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            input_img = input_img.to(device)\n            fake_mask = netG(input_img)\n\n            # Сопоставим имя файла с оригинальным индексом\n            real_idx = train_size + idx\n            base_name = os.path.splitext(dataset.filenames[real_idx])[0]  # например: \"img_012\"\n\n            # Обработка изображений\n            fake_mask_img = fake_mask.squeeze(0).squeeze(0).cpu()       # [1, 1, H, W] → [H, W]\n            input_vis = input_img.squeeze(0).cpu()                      # [1, C, H, W] → [C, H, W]\n            target_vis = target_img.squeeze(0).squeeze(0).cpu()         # [1, 1, H, W] → [H, W]\n\n            # Сохраняем отдельную предсказанную маску\n            plt.imsave(os.path.join(mask_dir, f'{base_name}_pred.png'), fake_mask_img, cmap='gray')\n\n            # Визуализация\n            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n\n            if input_vis.shape[0] == 3:  # RGB\n                axs[0].imshow(input_vis.permute(1, 2, 0) * 0.5 + 0.5)\n            else:  # Grayscale\n                axs[0].imshow(input_vis.squeeze(), cmap='gray')\n            axs[0].set_title('Input')\n\n            axs[1].imshow(target_vis, cmap='gray')\n            axs[1].set_title('Ground Truth')\n\n            axs[2].imshow(fake_mask_img, cmap='gray')\n            axs[2].set_title('Predicted Mask')\n\n            for ax in axs:\n                ax.axis('off')\n\n            plt.tight_layout()\n            plt.savefig(f'{save_dir}/sample_{idx:03d}.png')\n            plt.close()\n\n            if idx + 1 >= num_samples:\n                break\n\n\nif __name__ == '__main__':\n    inference(\n        checkpoint_path='generator_final.pth',\n        input_dir='/kaggle/input/dataset1/sliced images/input',\n        target_dir='/kaggle/input/dataset1/sliced images/target',\n        save_dir='predictions',\n        num_samples=264\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:56:34.409891Z","iopub.execute_input":"2025-04-29T17:56:34.410196Z","iopub.status.idle":"2025-04-29T17:58:16.741182Z","shell.execute_reply.started":"2025-04-29T17:56:34.410174Z","shell.execute_reply":"2025-04-29T17:58:16.740541Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2036143785.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  netG.load_state_dict(torch.load(checkpoint_path, map_location=device))\n100%|█████████▉| 263/264 [01:41<00:00,  2.58it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nimport os\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport numpy as np\nfrom skimage.metrics import structural_similarity as ssim_func\nfrom math import log10\nimport csv\n\ndef compute_metrics(pred, target):\n    pred = (pred > 0).astype(np.uint8)\n    target = (target > 0).astype(np.uint8)\n\n    intersection = np.logical_and(pred, target).sum()\n    union = np.logical_or(pred, target).sum()\n\n    dice = 2 * intersection / (pred.sum() + target.sum() + 1e-8)\n    iou = intersection / (union + 1e-8)\n    mae = np.mean(np.abs(pred - target))\n    rmse = np.sqrt(np.mean((pred - target) ** 2))\n    ssim = ssim_func(target, pred, data_range=1)\n\n    mse = np.mean((pred - target) ** 2)\n    psnr = 20 * log10(1.0) - 10 * log10(mse + 1e-8)  # Assuming pixel values in [0, 1]\n\n    return dice, iou, mae, rmse, ssim, psnr\n\ndef inference_with_metrics(checkpoint_path, input_dir, target_dir, save_dir='predictions'):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Загрузка модели\n    netG = UNet().to(device)\n    netG.load_state_dict(torch.load(checkpoint_path, map_location=device))\n    netG.eval()\n\n    os.makedirs(save_dir, exist_ok=True)\n\n    total_dice = total_iou = total_mae = total_rmse = total_ssim = total_psnr = 0\n\n    with torch.no_grad():\n        for idx, (input_img, target_img) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            input_img = input_img.to(device)\n            fake_mask = netG(input_img)\n\n            fake_mask_np = fake_mask.squeeze().cpu().numpy()\n            target_np = target_img.squeeze().cpu().numpy()\n\n            # Бинаризация\n            fake_mask_np_bin = (fake_mask_np > 0).astype(np.uint8)\n            target_np_bin = (target_np > 0).astype(np.uint8)\n\n            # Метрики\n            dice, iou, mae, rmse, ssim, psnr = compute_metrics(fake_mask_np_bin, target_np_bin)\n            total_dice += dice\n            total_iou += iou\n            total_mae += mae\n            total_rmse += rmse\n            total_ssim += ssim\n            total_psnr += psnr\n\n    N = len(test_loader)\n    avg_dice = total_dice / N\n    avg_iou = total_iou / N\n    avg_mae = total_mae / N\n    avg_rmse = total_rmse / N\n    avg_ssim = total_ssim / N\n    avg_psnr = total_psnr / N\n\n    print(f\"\\n📊 Metrics on Test Set:\")\n    print(f\"Dice:  {avg_dice:.4f}\")\n    print(f\"IoU:   {avg_iou:.4f}\")\n    print(f\"MAE:   {avg_mae:.4f}\")\n    print(f\"RMSE:  {avg_rmse:.4f}\")\n    print(f\"SSIM:  {avg_ssim:.4f}\")\n    print(f\"PSNR:  {avg_psnr:.4f}\")\n\n    # Сохранение в CSV\n    csv_path = os.path.join(save_dir, 'metrics.csv')\n    with open(csv_path, mode='w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Metric', 'Value'])\n        writer.writerow(['Dice', avg_dice])\n        writer.writerow(['IoU', avg_iou])\n        writer.writerow(['MAE', avg_mae])\n        writer.writerow(['RMSE', avg_rmse])\n        writer.writerow(['SSIM', avg_ssim])\n        writer.writerow(['PSNR', avg_psnr])\n\nif __name__ == '__main__':\n    inference_with_metrics(\n        checkpoint_path='generator_final.pth',\n        input_dir='/kaggle/input/dataset1/sliced images/input',\n        target_dir='/kaggle/input/dataset1/sliced images/target',\n        save_dir='predictions'\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T18:20:05.426191Z","iopub.execute_input":"2025-04-29T18:20:05.426477Z","iopub.status.idle":"2025-04-29T18:20:25.146071Z","shell.execute_reply.started":"2025-04-29T18:20:05.426456Z","shell.execute_reply":"2025-04-29T18:20:25.145333Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/4276485695.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  netG.load_state_dict(torch.load(checkpoint_path, map_location=device))\n100%|██████████| 264/264 [00:18<00:00, 13.91it/s]","output_type":"stream"},{"name":"stdout","text":"\n📊 Metrics on Test Set:\nDice:  0.8333\nIoU:   0.7273\nMAE:   21.0411\nRMSE:  0.3929\nSSIM:  0.5130\nPSNR:  8.3518\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive('/kaggle/working/output', 'zip', '/kaggle/working')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T18:21:33.958532Z","iopub.execute_input":"2025-04-29T18:21:33.958817Z","iopub.status.idle":"2025-04-29T18:23:41.788594Z","shell.execute_reply.started":"2025-04-29T18:21:33.958797Z","shell.execute_reply":"2025-04-29T18:23:41.788002Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/output.zip'"},"metadata":{}}],"execution_count":24}]}